{"cells":[{"cell_type":"markdown","metadata":{},"source":["# **HW2 : Decision Tree and Random Forest**\n","In *assignment 2*, you need to finish :\n","\n","1. Basic Part : Implement a **Decision Tree** model and predict whether the patients in the validation set have diabetes\n","> * Step 1 : Load the input data\n","> * Step 2 : Calculate the Entropy and Information Gain\n","> * Step 3 : Find the Best Split\n","> * Step 4 : Split into 2 branches\n","> * Step 5 : Build decision tree\n","> * Step 6 : Save the answers from step2 to step5\n","> * Step 7 : Split data into training set and validation set\n","> * Step 8 : Train a decision tree model with training set\n","> * Step 9 : Predict the cases in the *validation set* by using the model trained in *Step8*\n","> * Step 10 : Calculate the f1-score of your predictions in *Step9*\n","> * Step 11 : Write the Output File\n","\n","2. Advanced Part : Build a **Random Forest** model to make predictions\n","> * Step 1 : Load the input data\n","> * Step 2 : Load the test data\n","> * Step 3 : Build a random forest\n","> * Step 4 : Predict the cases in the test data by using the model trained in *Step3*\n","> * Step 5 : Save the predictions(from *Step 4*) in a csv file\n","\n"]},{"cell_type":"markdown","metadata":{"id":"wwVh8lYD4kbV"},"source":["# **Basic Part** (60%)\n","In this part, your need to implement a Decision Tree model by completing the following given functions.\n","\n","Also, you need to run these functions with the given input variables and save the output in a csv file **hw2_basic.csv**"]},{"cell_type":"markdown","metadata":{"id":"h2ibEyDa46X2"},"source":["## Import Packages\n","\n","\n","> Note : You **cannot** import any other packages in both basic part and advanced part\n","\n","\n","\n","\n"]},{"cell_type":"code","execution_count":2322,"metadata":{"id":"RMjaYVZD6kmb"},"outputs":[],"source":["import numpy as np\n","import pandas as pd\n","import math\n","import random\n","from numpy import sqrt\n","from sklearn.metrics import f1_score\n","from sklearn.metrics import accuracy_score"]},{"cell_type":"markdown","metadata":{"id":"zrQXqH475G8-"},"source":["## Step1: Load the input data\n","First, load the input file **hw2_input_basic.csv**"]},{"cell_type":"code","execution_count":2323,"metadata":{"id":"0n3gcL2l6kjb"},"outputs":[],"source":["input_data = pd.read_csv('hw2_input_basic.csv')"]},{"cell_type":"markdown","metadata":{"id":"BhtqUTG9Nlyz"},"source":["## Global attributes\n","Define the global attributes\n","> Note : You **cannot** modify the values of these attributes we given in the basic part"]},{"cell_type":"code","execution_count":2324,"metadata":{"id":"etfPC94oN_TO"},"outputs":[],"source":["max_depth = 2\n","depth = 0\n","min_samples_split = 2\n","n_features = input_data.shape[1] - 1"]},{"cell_type":"markdown","metadata":{"id":"V1FN1Z-tOFOo"},"source":["> You can add your own global attributes here"]},{"cell_type":"code","execution_count":2325,"metadata":{"id":"KQ-OYop8ONnv"},"outputs":[],"source":["pd.options.mode.chained_assignment = None "]},{"cell_type":"markdown","metadata":{"id":"Gey7t_Yx5YML"},"source":["## Step2 : Calculate the Entropy and Information Gain \n","Calculate the information gain and entropy values before separate data into left subtree and right subtree"]},{"cell_type":"code","execution_count":2326,"metadata":{"id":"hpdNz3ij6keH"},"outputs":[{"name":"stdout","output_type":"stream","text":["ans_entropy =  0.98714\n"]}],"source":["from math import log2\n","\n","def entropy(data):\n","  \"\"\"\n","  This function measures the amount of uncertainty in a probability distribution\n","  args: \n","  * data(type: DataFrame): the data you're calculating for the entropy\n","  return:\n","  * entropy_value(type: float): the data's entropy\n","  \"\"\"\n","\n","  total = data.shape[0]\n","  pos_case = data['diabetes_mellitus'].sum()\n","  \n","  if pos_case == 0:\n","    e = 0\n","  elif pos_case == total:\n","    e = 0\n","  else:\n","    p = pos_case/total\n","    e = -p*log2(p)-(1-p)*log2(1-p)\n","\n","  entropy_value = round(e,5)\n","  \n","  return entropy_value\n","\n","# [Note] You have to save the value of \"ans_entropy\" into the output file\n","ans_entropy = entropy(input_data)\n","print(\"ans_entropy = \", ans_entropy)"]},{"cell_type":"code","execution_count":2327,"metadata":{"id":"zCC_SiU26kbX"},"outputs":[{"name":"stdout","output_type":"stream","text":["ans_informationGain =  0.08346\n"]}],"source":["def information_gain(data, mask):\n","  \"\"\"\n","  This function will calculate the information gain\n","  args:\n","  * data(type: DataFrame): the data you're calculating for the information gain\n","  * mask(type: Series): partition information(left/right) of current input data, \n","    - boolean 1(True) represents split to left subtree\n","    - boolean 0(False) represents split to right subtree\n","  return:\n","  * ig(type: float): the information gain you can obtain by classify data with this given mask\n","  \"\"\"\n","  #Split data base on mask\n","  left_tree_true = data[mask]\n","  right_tree_false = data[~mask]\n","\n","  #Calculate the number of cases in left and right subtree respectively\n","  n_left_tree = left_tree_true.shape[0]\n","  n_right_tree = right_tree_false.shape[0]\n","  n_total = data.shape[0]\n","\n","  #Calculate the weight of left and right subtree \n","  weight_left = n_left_tree/n_total\n","  weight_right = n_right_tree/n_total\n","\n","  #Claculate the entropy of left and right subtrees\n","  left_entropy = entropy(left_tree_true)\n","  right_entropy = entropy(right_tree_false)\n","\n","  entropy_before = entropy(data)\n","  entropy_after = weight_left * left_entropy + weight_right * right_entropy\n","  \n","  ig = round(entropy_before - entropy_after,5)\n","\n","  return ig\n","\n","# [Note] You have to save the value of \"ans_informationGain\" into your output file\n","temp1 = np.zeros((int(input_data.shape[0]/4), 1), dtype=bool)\n","temp2 = np.ones(((input_data.shape[0]-int(input_data.shape[0]/4), 1)), dtype=bool)\n","temp_mask = np.concatenate((temp1, temp2))\n","df_mask = pd.DataFrame(temp_mask, columns=['mask'])\n","ans_informationGain = information_gain(input_data, df_mask['mask'])\n","print(\"ans_informationGain = \", ans_informationGain)"]},{"cell_type":"markdown","metadata":{"id":"9r8mrn7A55if"},"source":["## Step3 : Find the Best Split\n","Find the best split combination, **feature** and **threshold**, by calculating the information gain\n"]},{"cell_type":"code","execution_count":2328,"metadata":{"id":"D6gg7ig18XgM"},"outputs":[{"name":"stdout","output_type":"stream","text":["ans_ig =  0.35229\n","ans_value =  235.5\n","ans_name =  glucose_apache\n"]}],"source":["def find_best_split(data):\n","  \"\"\"\n","  This function will find the best split combination of data\n","  args:\n","  * data(type: DataFrame): the input data\n","  return\n","  * best_ig(type: float): the best information gain you obtain\n","  * best_threshold(type: float): the value that splits data into 2 branches\n","  * best_feature(type: string): the feature that splits data into 2 branches\n","  \"\"\"\n","\n","  n = n_features\n","  n_case = int(data.shape[0])\n","  df = data.iloc[0:n_case]\n","  features = df.columns\n","\n","  step = 1\n","\n","  table = np.zeros((3, n), dtype=float)\n","\n","  mask_frag = np.ones((step, 1), dtype=bool)\n","\n","  for i in range(n):\n","    mask = np.zeros((n_case, 1), dtype=bool)\n","    df['mask'] = mask\n","    for j in range(0,n_case-1,step):\n","      select = df.sort_values(by=[features[i]])\n","      mask[j:j+step] = mask_frag\n","      temp = select.T.columns\n","      index = int(temp[j+step-1])\n","      index2 = int(temp[j+step])\n","      a = select[features[i]][index]\n","      b = select[features[i]][index2]\n","      if a == b:\n","        continue\n","      select['mask'] = mask\n","      t_threshold = (select[features[i]][index]+select[features[i]][index2])/2\n","      select = select.sort_index()\n","      t_ig = information_gain(select, select['mask'])\n","      if table[0][i] < t_ig:\n","        table[0][i] = t_ig\n","        table[1][i] = t_threshold\n","        table[2][i] = i\n","  \n","  temp = pd.DataFrame(table)\n","  result = temp.sort_values(by=[0], ascending=False, axis=1).columns\n","  index = int(result[0])\n","  best_ig = temp[index][0]\n","  best_threshold = temp[index][1]\n","  best_feature = features[int(temp[index][2])]\n","\n","  return best_ig, best_threshold, best_feature\n","\n","\n","# [Note] You have to save the value of \"ans_ig\", \"ans_value\", and \"ans_name\" into the output file\n","ans_ig, ans_value, ans_name = find_best_split(input_data)\n","print(\"ans_ig = \", ans_ig)\n","print(\"ans_value = \", ans_value)\n","print(\"ans_name = \", ans_name)"]},{"cell_type":"markdown","metadata":{"id":"61hPUYvy6MTB"},"source":["## Step4 : Split into 2 branches\n","Using the best split combination you find in function *find_best_split()* to split data into Left Subtree and Right Subtree "]},{"cell_type":"code","execution_count":2329,"metadata":{"id":"KQRcjzCLCo4R"},"outputs":[{"name":"stdout","output_type":"stream","text":["ans_left =  10\n"]}],"source":["def make_partition(data, feature, threshold):\n","  \"\"\"\n","  This function will split the data into 2 branches\n","  args:\n","  * data(type: DataFrame): the input data\n","  * feature(type: string): the attribute(column name)\n","  * threshold(type: float): the threshold for splitting the data\n","  return:\n","  * left(type: DataFrame): the divided data that matches(less than or equal to) the assigned feature's threshold\n","  * right(type: DataFrame): the divided data that doesn't match the assigned feature's threshold\n","  \"\"\"\n","  n = int(data.shape[0])\n","  mask = np.zeros((n, 1), dtype=bool)\n","  valid_index = data.T.columns\n","  j = 0\n","  for i in valid_index:\n","    mask[j] = (data[feature][i] <= threshold)\n","    j = j + 1\n","  \n","\n","  left = data[mask]\n","  right = data[~mask]\n","\n","  return left, right\n","\n","# [Note] You have to save the value of \"ans_left\" into the output file\n","left, right = make_partition(input_data, 'age', 61.0)\n","ans_left = left.shape[0]\n","print(\"ans_left = \", ans_left)"]},{"cell_type":"markdown","metadata":{"id":"GLzy6Yhg802x"},"source":["## Step5 : Build Decision Tree\n","Use the above functions to implement the decision tree\n","\n","Instructions: \n","1.  If current depth < max_depth and the remaining number of samples > min_samples_split: continue to classify those samples\n","2.  Use function *find_best_split()* to find the best split combination\n","3.  If the obtained information gain is **greater than 0**: can build a deeper decision tree (add depth)\n","4. Use function *make_partition()* to split the data into two parts\n","5. Save the features and corresponding thresholds (starting from the root) used by the decision tree into *ans_features[]* and *ans_thresholds[]* respectively\n","\n","\n"]},{"cell_type":"code","execution_count":2330,"metadata":{"id":"_OAXVddKkvM2"},"outputs":[],"source":["def build_tree(data, max_depth, min_samples_split, depth):\n","  \"\"\"\n","  This function will build the decision tree\n","  args:\n","  * data(type: DataFrame): the data you want to apply to the decision tree\n","  * max_depth: the maximum depth of a decision tree\n","  * min_samples_split: the minimum number of instances required to do partition\n","  * depth: the height of the current decision tree\n","  return:\n","  * subtree: the decision tree structure including root, branch, and leaf (with the attributes and thresholds)\n","  \"\"\"\n","\n","  # check the condition of current depth and the remaining number of samples\n","  if depth < max_depth:\n","    # call find_best_split() to find the best combination\n","    ig, threshold, feature = find_best_split(data)\n","    # check the value of information gain is greater than 0 or not \n","    if ig > 0:\n","      # update the depth\n","      depth = depth + 1\n","      # call make_partition() to split the data into two parts\n","      left_st, right_st = make_partition(data, feature, threshold)\n","      # If there is no data split to the left tree OR no data split to the left tree\n","      if left_st.empty:\n","        # return the label of the majority\n","        t = right_st.shape[0]\n","        p = right_st['diabetes_mellitus'].sum()\n","        n = t-p\n","        label = int(p > n)\n","        return label\n","      elif right_st.empty: \n","        t = left_st.shape[0]\n","        p = left_st['diabetes_mellitus'].sum()\n","        n = t-p\n","        label = int(p > n)\n","        return label\n","      else:\n","        question = \"{} {} {}\".format(feature, \"<=\", threshold)\n","        subtree = {question: []}\n","        # call function build_tree() to recursively build the left subtree and right subtree\n","        left_subtree = build_tree(left_st, max_depth, min_samples_split, depth)\n","        right_subtree = build_tree(right_st, max_depth, min_samples_split, depth)\n","        if left_subtree == right_subtree:\n","          subtree = left_subtree\n","        else:\n","          subtree[question].append(left_subtree)\n","          subtree[question].append(right_subtree)\n","    else:\n","      # return the label of the majority\n","      t = data.shape[0]\n","      p = data['diabetes_mellitus'].sum()\n","      n = t-p\n","      label = int(p > n)\n","      return label\n","  else:\n","    # return the label of the majority\n","    t = data.shape[0]\n","    p = data['diabetes_mellitus'].sum()\n","    n = t-p\n","    label = int(p > n)\n","    return label\n","\n","  return subtree"]},{"cell_type":"markdown","metadata":{"id":"qlIrw9Gu-M9-"},"source":["An example of the output from *build_tree()* \n","```\n","{'bmi <= 33.5': [1, {'age <= 68.5': [0, 1]}]}\n","```\n","Therefore, \n","```\n","ans_features = ['bmi', 'age']\n","ans_thresholds = [33.5, 68.5]\n","```\n","\n"]},{"cell_type":"code","execution_count":2331,"metadata":{"id":"QW8wm1rD9dlS"},"outputs":[{"data":{"text/plain":["{'glucose_apache <= 235.5': [{'heart_rate_apache <= 143.5': [0, 1]}, 1]}"]},"execution_count":2331,"metadata":{},"output_type":"execute_result"}],"source":["ans_features = []\n","ans_thresholds = []\n","\n","decisionTree = build_tree(input_data, max_depth, min_samples_split, depth)\n","decisionTree"]},{"cell_type":"code","execution_count":2332,"metadata":{"id":"v_n0BfNSGejN"},"outputs":[{"data":{"text/plain":["['glucose_apache', 'heart_rate_apache']"]},"execution_count":2332,"metadata":{},"output_type":"execute_result"}],"source":["def PreOrderSearch(tree,feature_queue,thresholds_queue):\n","    \n","    feature_q = feature_queue\n","    thresholds_q = thresholds_queue\n","\n","    for key in tree:\n","        feature_q.append(key.split(\" <= \")[0])\n","        thresholds_q.append(key.split(\" <= \")[1])\n","\n","        if type(tree[key][0]) == dict:\n","            feature_q, thresholds_q = PreOrderSearch(tree[key][0], feature_q, thresholds_q)\n","\n","        if type(tree[key][1]) == dict:\n","            feature_q, thresholds_q = PreOrderSearch(tree[key][1], feature_q, thresholds_q)\n","    \n","    return feature_q, thresholds_q\n","\n","ans_features, ans_thresholds = PreOrderSearch(decisionTree,[],[])\n","\n","# [Note] You have to save the features in the \"decisionTree\" structure (from root to branch and leaf) into the output file\n","ans_features"]},{"cell_type":"code","execution_count":2333,"metadata":{"id":"D6H9zkN_GgK-"},"outputs":[{"data":{"text/plain":["['235.5', '143.5']"]},"execution_count":2333,"metadata":{},"output_type":"execute_result"}],"source":["# [Note] You have to save the corresponding thresholds for the features in the \"ans_features\" list into the output file\n","ans_thresholds"]},{"cell_type":"markdown","metadata":{"id":"rP0SU7tTweOX"},"source":["## Step6 : Save answers"]},{"cell_type":"code","execution_count":2334,"metadata":{"id":"sDO36kKEwh6C"},"outputs":[],"source":["basic = []\n","basic.append(ans_entropy)\n","basic.append(ans_informationGain)\n","basic.append(ans_ig)\n","basic.append(ans_value)\n","basic.append(ans_name)\n","basic.append(ans_left)\n","for i in range(len(ans_features)):\n","  basic.append(ans_features[i])\n","for m in range(len(ans_thresholds)):\n","  basic.append(ans_thresholds[m])"]},{"cell_type":"markdown","metadata":{"id":"7DotyrSZjYKi"},"source":["## Step7 : Split data\n","Split data into training set and validation set\n","> Note: We have split the data into training set and validation. You **cannot** change the distribution of the data."]},{"cell_type":"code","execution_count":2335,"metadata":{"id":"WjNM-n4i5mlG"},"outputs":[{"name":"stdout","output_type":"stream","text":["(30, 10)\n","(20, 10)\n","(10, 10)\n"]}],"source":["num_train = 20\n","num_validation = 10\n","\n","training_data = input_data.iloc[:num_train]\n","validation_data = input_data.iloc[-num_validation:]\n","\n","y_train = training_data[[\"diabetes_mellitus\"]]\n","x_train = training_data.drop(['diabetes_mellitus'], axis=1)\n","y_validation = validation_data[[\"diabetes_mellitus\"]]\n","x_validation = validation_data.drop(['diabetes_mellitus'], axis=1)\n","y_validation = y_validation.values.flatten()\n","\n","print(input_data.shape)\n","print(training_data.shape)\n","print(validation_data.shape)"]},{"cell_type":"markdown","metadata":{"id":"GfKSt2gH74Uu"},"source":["## Step8 to Step10 : Make predictions with a decision tree"]},{"cell_type":"markdown","metadata":{"id":"BZqSVoJ48a3-"},"source":["Define the attributions of the decision tree\n","> You **cannot** modify the values of these attributes in this part"]},{"cell_type":"code","execution_count":2336,"metadata":{"id":"vSlZ7FVB8eau"},"outputs":[],"source":["max_depth = 2\n","depth = 0\n","min_samples_split = 2\n","n_features = x_train.shape[1]"]},{"cell_type":"markdown","metadata":{"id":"FrK-YqLmLH8p"},"source":["We have finished the function '*classify_data()*' below, however, you can modify this function if you prefer completing it on your own way."]},{"cell_type":"code","execution_count":2337,"metadata":{"id":"0piZ0blpFXVq"},"outputs":[],"source":["def classify_data(instance, tree):\n","  \"\"\"\n","  This function will predict/classify the input instance\n","  args:\n","  * instance: a instance(case) to be predicted\n","  return:\n","  * answer: the prediction result (the classification result)\n","  \"\"\"\n","  equation = list(tree.keys())[0]\n","  if equation.split()[1] == '<=':\n","    temp_feature = equation.split()[0]\n","    temp_threshold = equation.split()[2]\n","    if instance[temp_feature] > float(temp_threshold):\n","      answer = tree[equation][1]\n","    else:\n","      answer = tree[equation][0]\n","  else:\n","    if instance[equation.split()[0]] in (equation.split()[2]):\n","      answer = tree[equation][0]\n","    else:\n","      answer = tree[equation][1]\n","\n","  if not isinstance(answer, dict):\n","    return answer\n","  else:\n","    return classify_data(instance, answer)\n","\n","\n","def make_prediction(tree, data):\n","  \"\"\"\n","  This function will use your pre-trained decision tree to predict the labels of all instances in data\n","  args:\n","  * tree: the decision tree\n","  * data: the data to predict\n","  return:\n","  * y_prediction: the predictions\n","  \"\"\"\n","  y_prediction = []\n","  \n","  valid_check = data.T.columns\n","\n","  # [Note] You can call the function classify_data() to predict the label of each instance\n","  for i in list(valid_check):\n","    \n","    y_prediction.append(classify_data(data.loc[i], tree))\n","  \n","  return y_prediction\n","\n","def calculate_score(y_true, y_pred):\n","  \"\"\"\n","  This function will calculate the f1-score of the predictions\n","  args:\n","  * y_true: the ground truth\n","  * y_pred: the predictions\n","  return:\n","  * score: the f1-score\n","  \"\"\"\n","  up = (y_true * y_pred).sum()\n","  \n","  down = y_true.sum() + np.array(y_pred).sum()\n","\n","  score = round(2*up/down, 4)\n","  \n","  return score"]},{"cell_type":"code","execution_count":2338,"metadata":{"id":"3IEu3z3s9TDu"},"outputs":[{"name":"stdout","output_type":"stream","text":["ans_f1score =  0.6667\n"]}],"source":["decision_tree = build_tree(training_data, max_depth, min_samples_split, depth)\n","\n","y_pred = make_prediction(decision_tree, x_validation)\n","\n","# [Note] You have to save the value of \"ans_f1score\" the your output file\n","\n","ans_f1score = calculate_score(y_validation, y_pred)\n","\n","print(\"ans_f1score = \", ans_f1score)"]},{"cell_type":"markdown","metadata":{"id":"IzzOKOwn-kod"},"source":["## Step11 : Write the Output File\n","Save all of your answers in a csv file, named as **hw2_basic.csv**"]},{"cell_type":"code","execution_count":2339,"metadata":{"id":"p0zsaWPL2qXn"},"outputs":[{"name":"stdout","output_type":"stream","text":["[0.98714, 0.08346, 0.35229, 235.5, 'glucose_apache', 10, 'glucose_apache', 'heart_rate_apache', '235.5', '143.5', 0.6667]\n"]}],"source":["ans_path = 'hw2_basic.csv'\n","\n","# [Note] You have to save the value of \"ans_f1score\" into the output file\n","basic.append(ans_f1score)\n","print(basic)\n","\n","pd.DataFrame(basic).to_csv(ans_path, header = None, index = None)"]},{"cell_type":"markdown","metadata":{"id":"tV25IjM7_aEn"},"source":["# **Advanced Part** (35%)"]},{"cell_type":"markdown","metadata":{"id":"knH1Ih0Pha7X"},"source":["## Step1: Load the input data\n","First, load the input file **hw2_input_advanced.csv**"]},{"cell_type":"code","execution_count":2340,"metadata":{"id":"FthBdLxRhi9W"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>bmi</th>\n","      <th>gender</th>\n","      <th>height</th>\n","      <th>weight</th>\n","      <th>arf_apache</th>\n","      <th>bun_apache</th>\n","      <th>creatinine_apache</th>\n","      <th>gcs_eyes_apache</th>\n","      <th>gcs_motor_apache</th>\n","      <th>...</th>\n","      <th>intubated_apache</th>\n","      <th>map_apache</th>\n","      <th>resprate_apache</th>\n","      <th>sodium_apache</th>\n","      <th>temp_apache</th>\n","      <th>ventilated_apache</th>\n","      <th>wbc_apache</th>\n","      <th>apache_4a_hospital_death_prob</th>\n","      <th>apache_4a_icu_death_prob</th>\n","      <th>diabetes_mellitus</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>72.0</td>\n","      <td>35.027162</td>\n","      <td>1</td>\n","      <td>188.0</td>\n","      <td>123.8</td>\n","      <td>0.0</td>\n","      <td>34.0</td>\n","      <td>1.41</td>\n","      <td>4.0</td>\n","      <td>6.0</td>\n","      <td>...</td>\n","      <td>1.0</td>\n","      <td>58.0</td>\n","      <td>5.0</td>\n","      <td>134.0</td>\n","      <td>36.20</td>\n","      <td>1.0</td>\n","      <td>7.0</td>\n","      <td>0.20</td>\n","      <td>0.12</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>68.0</td>\n","      <td>23.994027</td>\n","      <td>1</td>\n","      <td>180.3</td>\n","      <td>78.0</td>\n","      <td>0.0</td>\n","      <td>19.0</td>\n","      <td>1.56</td>\n","      <td>4.0</td>\n","      <td>6.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>130.0</td>\n","      <td>26.0</td>\n","      <td>139.0</td>\n","      <td>35.90</td>\n","      <td>0.0</td>\n","      <td>18.7</td>\n","      <td>0.05</td>\n","      <td>0.02</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>54.0</td>\n","      <td>29.566546</td>\n","      <td>1</td>\n","      <td>188.0</td>\n","      <td>104.5</td>\n","      <td>0.0</td>\n","      <td>34.0</td>\n","      <td>1.66</td>\n","      <td>4.0</td>\n","      <td>6.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>131.0</td>\n","      <td>28.0</td>\n","      <td>136.0</td>\n","      <td>36.30</td>\n","      <td>0.0</td>\n","      <td>23.7</td>\n","      <td>0.06</td>\n","      <td>0.04</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>42.0</td>\n","      <td>16.261908</td>\n","      <td>1</td>\n","      <td>182.9</td>\n","      <td>54.4</td>\n","      <td>0.0</td>\n","      <td>30.0</td>\n","      <td>1.21</td>\n","      <td>4.0</td>\n","      <td>6.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>137.0</td>\n","      <td>8.0</td>\n","      <td>135.0</td>\n","      <td>36.30</td>\n","      <td>0.0</td>\n","      <td>7.1</td>\n","      <td>0.01</td>\n","      <td>0.00</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>82.0</td>\n","      <td>24.017768</td>\n","      <td>0</td>\n","      <td>162.6</td>\n","      <td>63.5</td>\n","      <td>0.0</td>\n","      <td>10.0</td>\n","      <td>0.75</td>\n","      <td>4.0</td>\n","      <td>6.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>54.0</td>\n","      <td>28.0</td>\n","      <td>138.0</td>\n","      <td>36.70</td>\n","      <td>1.0</td>\n","      <td>17.6</td>\n","      <td>0.07</td>\n","      <td>0.03</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>8374</th>\n","      <td>28.0</td>\n","      <td>29.034281</td>\n","      <td>1</td>\n","      <td>185.4</td>\n","      <td>99.8</td>\n","      <td>0.0</td>\n","      <td>11.0</td>\n","      <td>0.90</td>\n","      <td>4.0</td>\n","      <td>6.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>114.0</td>\n","      <td>37.0</td>\n","      <td>136.0</td>\n","      <td>37.05</td>\n","      <td>0.0</td>\n","      <td>17.2</td>\n","      <td>0.01</td>\n","      <td>0.00</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8375</th>\n","      <td>79.0</td>\n","      <td>21.583026</td>\n","      <td>0</td>\n","      <td>157.0</td>\n","      <td>53.2</td>\n","      <td>0.0</td>\n","      <td>17.0</td>\n","      <td>0.71</td>\n","      <td>4.0</td>\n","      <td>6.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>50.0</td>\n","      <td>24.0</td>\n","      <td>147.0</td>\n","      <td>36.80</td>\n","      <td>0.0</td>\n","      <td>5.4</td>\n","      <td>0.04</td>\n","      <td>0.02</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>8376</th>\n","      <td>76.0</td>\n","      <td>31.078941</td>\n","      <td>0</td>\n","      <td>167.6</td>\n","      <td>87.3</td>\n","      <td>1.0</td>\n","      <td>33.0</td>\n","      <td>4.62</td>\n","      <td>4.0</td>\n","      <td>6.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>44.0</td>\n","      <td>25.0</td>\n","      <td>143.0</td>\n","      <td>36.00</td>\n","      <td>0.0</td>\n","      <td>6.3</td>\n","      <td>0.08</td>\n","      <td>0.02</td>\n","      <td>1</td>\n","    </tr>\n","    <tr>\n","      <th>8377</th>\n","      <td>80.0</td>\n","      <td>43.165799</td>\n","      <td>1</td>\n","      <td>182.9</td>\n","      <td>144.4</td>\n","      <td>0.0</td>\n","      <td>27.0</td>\n","      <td>1.53</td>\n","      <td>4.0</td>\n","      <td>6.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>139.0</td>\n","      <td>41.0</td>\n","      <td>136.0</td>\n","      <td>36.50</td>\n","      <td>0.0</td>\n","      <td>7.2</td>\n","      <td>0.10</td>\n","      <td>0.05</td>\n","      <td>0</td>\n","    </tr>\n","    <tr>\n","      <th>8378</th>\n","      <td>67.0</td>\n","      <td>36.442429</td>\n","      <td>0</td>\n","      <td>157.5</td>\n","      <td>90.4</td>\n","      <td>0.0</td>\n","      <td>54.0</td>\n","      <td>1.34</td>\n","      <td>4.0</td>\n","      <td>6.0</td>\n","      <td>...</td>\n","      <td>0.0</td>\n","      <td>44.0</td>\n","      <td>30.0</td>\n","      <td>141.0</td>\n","      <td>36.60</td>\n","      <td>1.0</td>\n","      <td>13.5</td>\n","      <td>0.35</td>\n","      <td>0.20</td>\n","      <td>1</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>8379 rows × 25 columns</p>\n","</div>"],"text/plain":["       age        bmi  gender  height  weight  arf_apache  bun_apache  \\\n","0     72.0  35.027162       1   188.0   123.8         0.0        34.0   \n","1     68.0  23.994027       1   180.3    78.0         0.0        19.0   \n","2     54.0  29.566546       1   188.0   104.5         0.0        34.0   \n","3     42.0  16.261908       1   182.9    54.4         0.0        30.0   \n","4     82.0  24.017768       0   162.6    63.5         0.0        10.0   \n","...    ...        ...     ...     ...     ...         ...         ...   \n","8374  28.0  29.034281       1   185.4    99.8         0.0        11.0   \n","8375  79.0  21.583026       0   157.0    53.2         0.0        17.0   \n","8376  76.0  31.078941       0   167.6    87.3         1.0        33.0   \n","8377  80.0  43.165799       1   182.9   144.4         0.0        27.0   \n","8378  67.0  36.442429       0   157.5    90.4         0.0        54.0   \n","\n","      creatinine_apache  gcs_eyes_apache  gcs_motor_apache  ...  \\\n","0                  1.41              4.0               6.0  ...   \n","1                  1.56              4.0               6.0  ...   \n","2                  1.66              4.0               6.0  ...   \n","3                  1.21              4.0               6.0  ...   \n","4                  0.75              4.0               6.0  ...   \n","...                 ...              ...               ...  ...   \n","8374               0.90              4.0               6.0  ...   \n","8375               0.71              4.0               6.0  ...   \n","8376               4.62              4.0               6.0  ...   \n","8377               1.53              4.0               6.0  ...   \n","8378               1.34              4.0               6.0  ...   \n","\n","      intubated_apache  map_apache  resprate_apache  sodium_apache  \\\n","0                  1.0        58.0              5.0          134.0   \n","1                  0.0       130.0             26.0          139.0   \n","2                  0.0       131.0             28.0          136.0   \n","3                  0.0       137.0              8.0          135.0   \n","4                  0.0        54.0             28.0          138.0   \n","...                ...         ...              ...            ...   \n","8374               0.0       114.0             37.0          136.0   \n","8375               0.0        50.0             24.0          147.0   \n","8376               0.0        44.0             25.0          143.0   \n","8377               0.0       139.0             41.0          136.0   \n","8378               0.0        44.0             30.0          141.0   \n","\n","      temp_apache  ventilated_apache  wbc_apache  \\\n","0           36.20                1.0         7.0   \n","1           35.90                0.0        18.7   \n","2           36.30                0.0        23.7   \n","3           36.30                0.0         7.1   \n","4           36.70                1.0        17.6   \n","...           ...                ...         ...   \n","8374        37.05                0.0        17.2   \n","8375        36.80                0.0         5.4   \n","8376        36.00                0.0         6.3   \n","8377        36.50                0.0         7.2   \n","8378        36.60                1.0        13.5   \n","\n","      apache_4a_hospital_death_prob  apache_4a_icu_death_prob  \\\n","0                              0.20                      0.12   \n","1                              0.05                      0.02   \n","2                              0.06                      0.04   \n","3                              0.01                      0.00   \n","4                              0.07                      0.03   \n","...                             ...                       ...   \n","8374                           0.01                      0.00   \n","8375                           0.04                      0.02   \n","8376                           0.08                      0.02   \n","8377                           0.10                      0.05   \n","8378                           0.35                      0.20   \n","\n","      diabetes_mellitus  \n","0                     1  \n","1                     1  \n","2                     1  \n","3                     1  \n","4                     0  \n","...                 ...  \n","8374                  0  \n","8375                  1  \n","8376                  1  \n","8377                  0  \n","8378                  1  \n","\n","[8379 rows x 25 columns]"]},"execution_count":2340,"metadata":{},"output_type":"execute_result"}],"source":["advanced_data = pd.read_csv('hw2_input_advanced.csv')\n","advanced_data"]},{"cell_type":"markdown","metadata":{"id":"vqLH49oBndRh"},"source":["You can split *advanced_data* into training set and validaiton set"]},{"cell_type":"code","execution_count":2341,"metadata":{"id":"9l0hLPVjncam"},"outputs":[],"source":["num_train = int(advanced_data.shape[0]*0.8)\n","num_validation = advanced_data.shape[0] - num_train\n","\n","training_data = advanced_data.iloc[:num_train]\n","validation_data = advanced_data.iloc[-num_validation:]\n","\n","y_train = training_data[[\"diabetes_mellitus\"]]\n","x_train = training_data.drop(['diabetes_mellitus'], axis=1)\n","y_validation = validation_data[[\"diabetes_mellitus\"]]\n","x_validation = validation_data.drop(['diabetes_mellitus'], axis=1)\n","y_validation = y_validation.values.flatten()"]},{"cell_type":"markdown","metadata":{"id":"tFgbUY_ajVOK"},"source":["## Step2 : Load the test data\n","Load the input file **hw2_input_test.csv** to make predictions with the pre-trained random forest model"]},{"cell_type":"code","execution_count":2342,"metadata":{"id":"3hW542KWNxVF"},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>age</th>\n","      <th>bmi</th>\n","      <th>gender</th>\n","      <th>height</th>\n","      <th>weight</th>\n","      <th>arf_apache</th>\n","      <th>bun_apache</th>\n","      <th>creatinine_apache</th>\n","      <th>gcs_eyes_apache</th>\n","      <th>gcs_motor_apache</th>\n","      <th>...</th>\n","      <th>hematocrit_apache</th>\n","      <th>intubated_apache</th>\n","      <th>map_apache</th>\n","      <th>resprate_apache</th>\n","      <th>sodium_apache</th>\n","      <th>temp_apache</th>\n","      <th>ventilated_apache</th>\n","      <th>wbc_apache</th>\n","      <th>apache_4a_hospital_death_prob</th>\n","      <th>apache_4a_icu_death_prob</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>62</td>\n","      <td>32.866392</td>\n","      <td>1</td>\n","      <td>177.80</td>\n","      <td>103.9</td>\n","      <td>1</td>\n","      <td>31.0</td>\n","      <td>10.30</td>\n","      <td>4</td>\n","      <td>6</td>\n","      <td>...</td>\n","      <td>36.4</td>\n","      <td>0</td>\n","      <td>157</td>\n","      <td>26</td>\n","      <td>134</td>\n","      <td>36.1</td>\n","      <td>0</td>\n","      <td>4.56</td>\n","      <td>0.06</td>\n","      <td>0.03</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>82</td>\n","      <td>23.582766</td>\n","      <td>0</td>\n","      <td>157.50</td>\n","      <td>58.5</td>\n","      <td>0</td>\n","      <td>26.0</td>\n","      <td>0.54</td>\n","      <td>3</td>\n","      <td>4</td>\n","      <td>...</td>\n","      <td>32.8</td>\n","      <td>0</td>\n","      <td>42</td>\n","      <td>25</td>\n","      <td>142</td>\n","      <td>36.1</td>\n","      <td>0</td>\n","      <td>6.00</td>\n","      <td>0.14</td>\n","      <td>0.06</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>61</td>\n","      <td>31.684520</td>\n","      <td>1</td>\n","      <td>172.70</td>\n","      <td>94.5</td>\n","      <td>0</td>\n","      <td>16.0</td>\n","      <td>1.11</td>\n","      <td>4</td>\n","      <td>6</td>\n","      <td>...</td>\n","      <td>35.3</td>\n","      <td>0</td>\n","      <td>129</td>\n","      <td>6</td>\n","      <td>131</td>\n","      <td>36.8</td>\n","      <td>0</td>\n","      <td>8.59</td>\n","      <td>0.05</td>\n","      <td>0.03</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>58</td>\n","      <td>45.156250</td>\n","      <td>0</td>\n","      <td>160.00</td>\n","      <td>115.6</td>\n","      <td>0</td>\n","      <td>19.0</td>\n","      <td>0.70</td>\n","      <td>1</td>\n","      <td>4</td>\n","      <td>...</td>\n","      <td>30.1</td>\n","      <td>1</td>\n","      <td>131</td>\n","      <td>23</td>\n","      <td>138</td>\n","      <td>34.9</td>\n","      <td>1</td>\n","      <td>16.03</td>\n","      <td>0.33</td>\n","      <td>0.22</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>74</td>\n","      <td>25.817016</td>\n","      <td>1</td>\n","      <td>172.70</td>\n","      <td>77.0</td>\n","      <td>0</td>\n","      <td>25.0</td>\n","      <td>0.93</td>\n","      <td>4</td>\n","      <td>6</td>\n","      <td>...</td>\n","      <td>34.5</td>\n","      <td>0</td>\n","      <td>55</td>\n","      <td>12</td>\n","      <td>135</td>\n","      <td>36.3</td>\n","      <td>0</td>\n","      <td>45.80</td>\n","      <td>0.12</td>\n","      <td>0.05</td>\n","    </tr>\n","    <tr>\n","      <th>...</th>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","      <td>...</td>\n","    </tr>\n","    <tr>\n","      <th>835</th>\n","      <td>73</td>\n","      <td>17.943584</td>\n","      <td>0</td>\n","      <td>157.48</td>\n","      <td>44.5</td>\n","      <td>0</td>\n","      <td>12.0</td>\n","      <td>0.30</td>\n","      <td>4</td>\n","      <td>6</td>\n","      <td>...</td>\n","      <td>33.8</td>\n","      <td>0</td>\n","      <td>129</td>\n","      <td>9</td>\n","      <td>144</td>\n","      <td>36.9</td>\n","      <td>0</td>\n","      <td>7.70</td>\n","      <td>0.02</td>\n","      <td>0.01</td>\n","    </tr>\n","    <tr>\n","      <th>836</th>\n","      <td>79</td>\n","      <td>29.049732</td>\n","      <td>1</td>\n","      <td>167.60</td>\n","      <td>81.6</td>\n","      <td>0</td>\n","      <td>48.0</td>\n","      <td>2.19</td>\n","      <td>4</td>\n","      <td>6</td>\n","      <td>...</td>\n","      <td>42.7</td>\n","      <td>0</td>\n","      <td>163</td>\n","      <td>9</td>\n","      <td>139</td>\n","      <td>36.4</td>\n","      <td>0</td>\n","      <td>10.77</td>\n","      <td>0.06</td>\n","      <td>0.03</td>\n","    </tr>\n","    <tr>\n","      <th>837</th>\n","      <td>85</td>\n","      <td>24.627827</td>\n","      <td>0</td>\n","      <td>152.40</td>\n","      <td>57.2</td>\n","      <td>0</td>\n","      <td>11.0</td>\n","      <td>0.48</td>\n","      <td>3</td>\n","      <td>5</td>\n","      <td>...</td>\n","      <td>29.5</td>\n","      <td>0</td>\n","      <td>67</td>\n","      <td>9</td>\n","      <td>139</td>\n","      <td>36.6</td>\n","      <td>0</td>\n","      <td>7.35</td>\n","      <td>0.16</td>\n","      <td>0.05</td>\n","    </tr>\n","    <tr>\n","      <th>838</th>\n","      <td>68</td>\n","      <td>32.510940</td>\n","      <td>1</td>\n","      <td>193.00</td>\n","      <td>121.1</td>\n","      <td>0</td>\n","      <td>14.0</td>\n","      <td>0.64</td>\n","      <td>4</td>\n","      <td>6</td>\n","      <td>...</td>\n","      <td>37.5</td>\n","      <td>0</td>\n","      <td>61</td>\n","      <td>10</td>\n","      <td>140</td>\n","      <td>36.9</td>\n","      <td>1</td>\n","      <td>16.02</td>\n","      <td>0.00</td>\n","      <td>0.00</td>\n","    </tr>\n","    <tr>\n","      <th>839</th>\n","      <td>48</td>\n","      <td>24.106828</td>\n","      <td>0</td>\n","      <td>157.50</td>\n","      <td>59.8</td>\n","      <td>0</td>\n","      <td>7.0</td>\n","      <td>0.33</td>\n","      <td>4</td>\n","      <td>6</td>\n","      <td>...</td>\n","      <td>32.3</td>\n","      <td>0</td>\n","      <td>111</td>\n","      <td>14</td>\n","      <td>139</td>\n","      <td>36.3</td>\n","      <td>0</td>\n","      <td>2.20</td>\n","      <td>0.01</td>\n","      <td>0.00</td>\n","    </tr>\n","  </tbody>\n","</table>\n","<p>840 rows × 24 columns</p>\n","</div>"],"text/plain":["     age        bmi  gender  height  weight  arf_apache  bun_apache  \\\n","0     62  32.866392       1  177.80   103.9           1        31.0   \n","1     82  23.582766       0  157.50    58.5           0        26.0   \n","2     61  31.684520       1  172.70    94.5           0        16.0   \n","3     58  45.156250       0  160.00   115.6           0        19.0   \n","4     74  25.817016       1  172.70    77.0           0        25.0   \n","..   ...        ...     ...     ...     ...         ...         ...   \n","835   73  17.943584       0  157.48    44.5           0        12.0   \n","836   79  29.049732       1  167.60    81.6           0        48.0   \n","837   85  24.627827       0  152.40    57.2           0        11.0   \n","838   68  32.510940       1  193.00   121.1           0        14.0   \n","839   48  24.106828       0  157.50    59.8           0         7.0   \n","\n","     creatinine_apache  gcs_eyes_apache  gcs_motor_apache  ...  \\\n","0                10.30                4                 6  ...   \n","1                 0.54                3                 4  ...   \n","2                 1.11                4                 6  ...   \n","3                 0.70                1                 4  ...   \n","4                 0.93                4                 6  ...   \n","..                 ...              ...               ...  ...   \n","835               0.30                4                 6  ...   \n","836               2.19                4                 6  ...   \n","837               0.48                3                 5  ...   \n","838               0.64                4                 6  ...   \n","839               0.33                4                 6  ...   \n","\n","     hematocrit_apache  intubated_apache  map_apache  resprate_apache  \\\n","0                 36.4                 0         157               26   \n","1                 32.8                 0          42               25   \n","2                 35.3                 0         129                6   \n","3                 30.1                 1         131               23   \n","4                 34.5                 0          55               12   \n","..                 ...               ...         ...              ...   \n","835               33.8                 0         129                9   \n","836               42.7                 0         163                9   \n","837               29.5                 0          67                9   \n","838               37.5                 0          61               10   \n","839               32.3                 0         111               14   \n","\n","     sodium_apache  temp_apache  ventilated_apache  wbc_apache  \\\n","0              134         36.1                  0        4.56   \n","1              142         36.1                  0        6.00   \n","2              131         36.8                  0        8.59   \n","3              138         34.9                  1       16.03   \n","4              135         36.3                  0       45.80   \n","..             ...          ...                ...         ...   \n","835            144         36.9                  0        7.70   \n","836            139         36.4                  0       10.77   \n","837            139         36.6                  0        7.35   \n","838            140         36.9                  1       16.02   \n","839            139         36.3                  0        2.20   \n","\n","     apache_4a_hospital_death_prob  apache_4a_icu_death_prob  \n","0                             0.06                      0.03  \n","1                             0.14                      0.06  \n","2                             0.05                      0.03  \n","3                             0.33                      0.22  \n","4                             0.12                      0.05  \n","..                             ...                       ...  \n","835                           0.02                      0.01  \n","836                           0.06                      0.03  \n","837                           0.16                      0.05  \n","838                           0.00                      0.00  \n","839                           0.01                      0.00  \n","\n","[840 rows x 24 columns]"]},"execution_count":2342,"metadata":{},"output_type":"execute_result"}],"source":["x_test = pd.read_csv('hw2_input_test.csv')\n","x_test"]},{"cell_type":"markdown","metadata":{"id":"mH-0DxyR9qWn"},"source":["## Step3 : Build a Random Forest"]},{"cell_type":"markdown","metadata":{"id":"8xbLxFW597FG"},"source":["Define the attributions of the random forest\n","> * You **can** modify the values of these attributes in advanced part\n","> * Each tree can have different attribute values\n","> * There must be **at least** 3 decision trees in the random forest model\n","> * Must use function *build_tree()* to build a random forest model\n","> * These are the parameters you can adjust : \n","\n","\n","    ```\n","    max_depth = \n","    depth = 0\n","    min_samples_split = \n","    \n","    # total number of trees in a random forest\n","    n_trees = \n","\n","    # number of features to train a decision tree\n","    n_features = \n","\n","    # the ratio to select the number of instances\n","    sample_size = \n","    n_samples = int(training_data.shape[0] * sample_size)\n","    ```\n","\n","\n"]},{"cell_type":"code","execution_count":2343,"metadata":{"id":"LD8ndJ8ymzG3"},"outputs":[],"source":["# Define the attributes\n","max_depth = 4\n","\n","depth = 0\n","\n","min_samples_split = 2\n","    \n","# total number of trees in a random forest\n","n_trees = 4\n","\n","# number of features to train a decision tree\n","n_features = 6\n","\n","# the ratio to select the number of instances\n","sample_size = 0.25\n","\n","n_samples = int(training_data.shape[0] * sample_size)"]},{"cell_type":"code","execution_count":2344,"metadata":{"id":"hVl66f1aU36-"},"outputs":[],"source":["def build_forest(data, n_trees, n_features, n_samples):\n","  \"\"\"\n","  This function will build a random forest.\n","  args:\n","  * data: all data that can be used to train a random forest\n","  * n_trees: total number of tree\n","  * n_features: number of features\n","  * n_samples: number of instances\n","  return:\n","  * forest: a random forest with 'n_trees' of decision tree\n","  \"\"\"\n","  forest = []\n","  # must reuse function build_tree()\n","  for j in range(n_trees):\n","    sel_data = data[j*n_samples:(j+1)*n_samples].T[j*n_features:(j+1)*n_features].T\n","    sel_data2 = data['diabetes_mellitus'][j*n_samples:(j+1)*n_samples]\n","    sel_data['diabetes_mellitus'] = sel_data2\n","    tree = build_tree(sel_data, max_depth, min_samples_split, depth)\n","    print(tree)\n","    forest.append(tree)\n","  return forest"]},{"cell_type":"code","execution_count":2345,"metadata":{"id":"zylo6C51m3OJ"},"outputs":[{"ename":"KeyboardInterrupt","evalue":"","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)","\u001b[1;32mc:\\Users\\KCChu\\Documents\\GitHub\\ML-Diabetes-Prediction\\hw2.ipynb Cell 47\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/KCChu/Documents/GitHub/ML-Diabetes-Prediction/hw2.ipynb#X66sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m forest \u001b[39m=\u001b[39m build_forest(training_data, n_trees, n_features, n_samples)\n","\u001b[1;32mc:\\Users\\KCChu\\Documents\\GitHub\\ML-Diabetes-Prediction\\hw2.ipynb Cell 47\u001b[0m in \u001b[0;36mbuild_forest\u001b[1;34m(data, n_trees, n_features, n_samples)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KCChu/Documents/GitHub/ML-Diabetes-Prediction/hw2.ipynb#X66sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m sel_data2 \u001b[39m=\u001b[39m data[\u001b[39m'\u001b[39m\u001b[39mdiabetes_mellitus\u001b[39m\u001b[39m'\u001b[39m][j\u001b[39m*\u001b[39mn_samples:(j\u001b[39m+\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m*\u001b[39mn_samples]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KCChu/Documents/GitHub/ML-Diabetes-Prediction/hw2.ipynb#X66sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m sel_data[\u001b[39m'\u001b[39m\u001b[39mdiabetes_mellitus\u001b[39m\u001b[39m'\u001b[39m] \u001b[39m=\u001b[39m sel_data2\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/KCChu/Documents/GitHub/ML-Diabetes-Prediction/hw2.ipynb#X66sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m tree \u001b[39m=\u001b[39m build_tree(sel_data, max_depth, min_samples_split, depth)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KCChu/Documents/GitHub/ML-Diabetes-Prediction/hw2.ipynb#X66sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m \u001b[39mprint\u001b[39m(tree)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KCChu/Documents/GitHub/ML-Diabetes-Prediction/hw2.ipynb#X66sZmlsZQ%3D%3D?line=19'>20</a>\u001b[0m forest\u001b[39m.\u001b[39mappend(tree)\n","\u001b[1;32mc:\\Users\\KCChu\\Documents\\GitHub\\ML-Diabetes-Prediction\\hw2.ipynb Cell 47\u001b[0m in \u001b[0;36mbuild_tree\u001b[1;34m(data, max_depth, min_samples_split, depth)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KCChu/Documents/GitHub/ML-Diabetes-Prediction/hw2.ipynb#X66sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39m# call function build_tree() to recursively build the left subtree and right subtree\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KCChu/Documents/GitHub/ML-Diabetes-Prediction/hw2.ipynb#X66sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m left_subtree \u001b[39m=\u001b[39m build_tree(left_st, max_depth, min_samples_split, depth)\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/KCChu/Documents/GitHub/ML-Diabetes-Prediction/hw2.ipynb#X66sZmlsZQ%3D%3D?line=41'>42</a>\u001b[0m right_subtree \u001b[39m=\u001b[39m build_tree(right_st, max_depth, min_samples_split, depth)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KCChu/Documents/GitHub/ML-Diabetes-Prediction/hw2.ipynb#X66sZmlsZQ%3D%3D?line=42'>43</a>\u001b[0m \u001b[39mif\u001b[39;00m left_subtree \u001b[39m==\u001b[39m right_subtree:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KCChu/Documents/GitHub/ML-Diabetes-Prediction/hw2.ipynb#X66sZmlsZQ%3D%3D?line=43'>44</a>\u001b[0m   subtree \u001b[39m=\u001b[39m left_subtree\n","\u001b[1;32mc:\\Users\\KCChu\\Documents\\GitHub\\ML-Diabetes-Prediction\\hw2.ipynb Cell 47\u001b[0m in \u001b[0;36mbuild_tree\u001b[1;34m(data, max_depth, min_samples_split, depth)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KCChu/Documents/GitHub/ML-Diabetes-Prediction/hw2.ipynb#X66sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m \u001b[39m# check the condition of current depth and the remaining number of samples\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KCChu/Documents/GitHub/ML-Diabetes-Prediction/hw2.ipynb#X66sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m \u001b[39mif\u001b[39;00m depth \u001b[39m<\u001b[39m max_depth:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KCChu/Documents/GitHub/ML-Diabetes-Prediction/hw2.ipynb#X66sZmlsZQ%3D%3D?line=14'>15</a>\u001b[0m   \u001b[39m# call find_best_split() to find the best combination\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/KCChu/Documents/GitHub/ML-Diabetes-Prediction/hw2.ipynb#X66sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m   ig, threshold, feature \u001b[39m=\u001b[39m find_best_split(data)\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KCChu/Documents/GitHub/ML-Diabetes-Prediction/hw2.ipynb#X66sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m   \u001b[39m# check the value of information gain is greater than 0 or not \u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KCChu/Documents/GitHub/ML-Diabetes-Prediction/hw2.ipynb#X66sZmlsZQ%3D%3D?line=17'>18</a>\u001b[0m   \u001b[39mif\u001b[39;00m ig \u001b[39m>\u001b[39m \u001b[39m0\u001b[39m:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KCChu/Documents/GitHub/ML-Diabetes-Prediction/hw2.ipynb#X66sZmlsZQ%3D%3D?line=18'>19</a>\u001b[0m     \u001b[39m# update the depth\u001b[39;00m\n","\u001b[1;32mc:\\Users\\KCChu\\Documents\\GitHub\\ML-Diabetes-Prediction\\hw2.ipynb Cell 47\u001b[0m in \u001b[0;36mfind_best_split\u001b[1;34m(data)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KCChu/Documents/GitHub/ML-Diabetes-Prediction/hw2.ipynb#X66sZmlsZQ%3D%3D?line=36'>37</a>\u001b[0m t_threshold \u001b[39m=\u001b[39m (select[features[i]][index]\u001b[39m+\u001b[39mselect[features[i]][index2])\u001b[39m/\u001b[39m\u001b[39m2\u001b[39m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KCChu/Documents/GitHub/ML-Diabetes-Prediction/hw2.ipynb#X66sZmlsZQ%3D%3D?line=37'>38</a>\u001b[0m select \u001b[39m=\u001b[39m select\u001b[39m.\u001b[39msort_index()\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/KCChu/Documents/GitHub/ML-Diabetes-Prediction/hw2.ipynb#X66sZmlsZQ%3D%3D?line=38'>39</a>\u001b[0m t_ig \u001b[39m=\u001b[39m information_gain(select, select[\u001b[39m'\u001b[39;49m\u001b[39mmask\u001b[39;49m\u001b[39m'\u001b[39;49m])\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KCChu/Documents/GitHub/ML-Diabetes-Prediction/hw2.ipynb#X66sZmlsZQ%3D%3D?line=39'>40</a>\u001b[0m \u001b[39mif\u001b[39;00m table[\u001b[39m0\u001b[39m][i] \u001b[39m<\u001b[39m t_ig:\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KCChu/Documents/GitHub/ML-Diabetes-Prediction/hw2.ipynb#X66sZmlsZQ%3D%3D?line=40'>41</a>\u001b[0m   table[\u001b[39m0\u001b[39m][i] \u001b[39m=\u001b[39m t_ig\n","\u001b[1;32mc:\\Users\\KCChu\\Documents\\GitHub\\ML-Diabetes-Prediction\\hw2.ipynb Cell 47\u001b[0m in \u001b[0;36minformation_gain\u001b[1;34m(data, mask)\u001b[0m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KCChu/Documents/GitHub/ML-Diabetes-Prediction/hw2.ipynb#X66sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m \u001b[39m#Split data base on mask\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KCChu/Documents/GitHub/ML-Diabetes-Prediction/hw2.ipynb#X66sZmlsZQ%3D%3D?line=12'>13</a>\u001b[0m left_tree_true \u001b[39m=\u001b[39m data[mask]\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/KCChu/Documents/GitHub/ML-Diabetes-Prediction/hw2.ipynb#X66sZmlsZQ%3D%3D?line=13'>14</a>\u001b[0m right_tree_false \u001b[39m=\u001b[39m data[\u001b[39m~\u001b[39;49mmask]\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KCChu/Documents/GitHub/ML-Diabetes-Prediction/hw2.ipynb#X66sZmlsZQ%3D%3D?line=15'>16</a>\u001b[0m \u001b[39m#Calculate the number of cases in left and right subtree respectively\u001b[39;00m\n\u001b[0;32m     <a href='vscode-notebook-cell:/c%3A/Users/KCChu/Documents/GitHub/ML-Diabetes-Prediction/hw2.ipynb#X66sZmlsZQ%3D%3D?line=16'>17</a>\u001b[0m n_left_tree \u001b[39m=\u001b[39m left_tree_true\u001b[39m.\u001b[39mshape[\u001b[39m0\u001b[39m]\n","File \u001b[1;32mc:\\ProgramData\\Miniconda3\\lib\\site-packages\\pandas\\core\\frame.py:3496\u001b[0m, in \u001b[0;36mDataFrame.__getitem__\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3494\u001b[0m \u001b[39m# Do we have a (boolean) 1d indexer?\u001b[39;00m\n\u001b[0;32m   3495\u001b[0m \u001b[39mif\u001b[39;00m com\u001b[39m.\u001b[39mis_bool_indexer(key):\n\u001b[1;32m-> 3496\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_getitem_bool_array(key)\n\u001b[0;32m   3498\u001b[0m \u001b[39m# We are left with two options: a single key, and a collection of keys,\u001b[39;00m\n\u001b[0;32m   3499\u001b[0m \u001b[39m# We interpret tuples as collections only for non-MultiIndex\u001b[39;00m\n\u001b[0;32m   3500\u001b[0m is_single_key \u001b[39m=\u001b[39m \u001b[39misinstance\u001b[39m(key, \u001b[39mtuple\u001b[39m) \u001b[39mor\u001b[39;00m \u001b[39mnot\u001b[39;00m is_list_like(key)\n","File \u001b[1;32mc:\\ProgramData\\Miniconda3\\lib\\site-packages\\pandas\\core\\frame.py:3551\u001b[0m, in \u001b[0;36mDataFrame._getitem_bool_array\u001b[1;34m(self, key)\u001b[0m\n\u001b[0;32m   3549\u001b[0m key \u001b[39m=\u001b[39m check_bool_indexer(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mindex, key)\n\u001b[0;32m   3550\u001b[0m indexer \u001b[39m=\u001b[39m key\u001b[39m.\u001b[39mnonzero()[\u001b[39m0\u001b[39m]\n\u001b[1;32m-> 3551\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_take_with_is_copy(indexer, axis\u001b[39m=\u001b[39;49m\u001b[39m0\u001b[39;49m)\n","File \u001b[1;32mc:\\ProgramData\\Miniconda3\\lib\\site-packages\\pandas\\core\\generic.py:3728\u001b[0m, in \u001b[0;36mNDFrame._take_with_is_copy\u001b[1;34m(self, indices, axis)\u001b[0m\n\u001b[0;32m   3720\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39m_take_with_is_copy\u001b[39m(\u001b[39mself\u001b[39m: NDFrameT, indices, axis\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m NDFrameT:\n\u001b[0;32m   3721\u001b[0m     \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m   3722\u001b[0m \u001b[39m    Internal version of the `take` method that sets the `_is_copy`\u001b[39;00m\n\u001b[0;32m   3723\u001b[0m \u001b[39m    attribute to keep track of the parent dataframe (using in indexing\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m   3726\u001b[0m \u001b[39m    See the docstring of `take` for full explanation of the parameters.\u001b[39;00m\n\u001b[0;32m   3727\u001b[0m \u001b[39m    \"\"\"\u001b[39;00m\n\u001b[1;32m-> 3728\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mtake(indices\u001b[39m=\u001b[39;49mindices, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[0;32m   3729\u001b[0m     \u001b[39m# Maybe set copy if we didn't actually change the index.\u001b[39;00m\n\u001b[0;32m   3730\u001b[0m     \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m result\u001b[39m.\u001b[39m_get_axis(axis)\u001b[39m.\u001b[39mequals(\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_get_axis(axis)):\n","File \u001b[1;32mc:\\ProgramData\\Miniconda3\\lib\\site-packages\\pandas\\core\\generic.py:3715\u001b[0m, in \u001b[0;36mNDFrame.take\u001b[1;34m(self, indices, axis, is_copy, **kwargs)\u001b[0m\n\u001b[0;32m   3711\u001b[0m nv\u001b[39m.\u001b[39mvalidate_take((), kwargs)\n\u001b[0;32m   3713\u001b[0m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_consolidate_inplace()\n\u001b[1;32m-> 3715\u001b[0m new_data \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_mgr\u001b[39m.\u001b[39;49mtake(\n\u001b[0;32m   3716\u001b[0m     indices, axis\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_get_block_manager_axis(axis), verify\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m\n\u001b[0;32m   3717\u001b[0m )\n\u001b[0;32m   3718\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_constructor(new_data)\u001b[39m.\u001b[39m__finalize__(\u001b[39mself\u001b[39m, method\u001b[39m=\u001b[39m\u001b[39m\"\u001b[39m\u001b[39mtake\u001b[39m\u001b[39m\"\u001b[39m)\n","File \u001b[1;32mc:\\ProgramData\\Miniconda3\\lib\\site-packages\\pandas\\core\\internals\\managers.py:899\u001b[0m, in \u001b[0;36mBaseBlockManager.take\u001b[1;34m(self, indexer, axis, verify)\u001b[0m\n\u001b[0;32m    896\u001b[0m n \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mshape[axis]\n\u001b[0;32m    897\u001b[0m indexer \u001b[39m=\u001b[39m maybe_convert_indices(indexer, n, verify\u001b[39m=\u001b[39mverify)\n\u001b[1;32m--> 899\u001b[0m new_labels \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49maxes[axis]\u001b[39m.\u001b[39;49mtake(indexer)\n\u001b[0;32m    900\u001b[0m \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mreindex_indexer(\n\u001b[0;32m    901\u001b[0m     new_axis\u001b[39m=\u001b[39mnew_labels,\n\u001b[0;32m    902\u001b[0m     indexer\u001b[39m=\u001b[39mindexer,\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m    905\u001b[0m     consolidate\u001b[39m=\u001b[39m\u001b[39mFalse\u001b[39;00m,\n\u001b[0;32m    906\u001b[0m )\n","File \u001b[1;32mc:\\ProgramData\\Miniconda3\\lib\\site-packages\\pandas\\core\\indexes\\base.py:1113\u001b[0m, in \u001b[0;36mIndex.take\u001b[1;34m(self, indices, axis, allow_fill, fill_value, **kwargs)\u001b[0m\n\u001b[0;32m   1111\u001b[0m values \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_values\n\u001b[0;32m   1112\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(values, np\u001b[39m.\u001b[39mndarray):\n\u001b[1;32m-> 1113\u001b[0m     taken \u001b[39m=\u001b[39m algos\u001b[39m.\u001b[39;49mtake(\n\u001b[0;32m   1114\u001b[0m         values, indices, allow_fill\u001b[39m=\u001b[39;49mallow_fill, fill_value\u001b[39m=\u001b[39;49m\u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49m_na_value\n\u001b[0;32m   1115\u001b[0m     )\n\u001b[0;32m   1116\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1117\u001b[0m     \u001b[39m# algos.take passes 'axis' keyword which not all EAs accept\u001b[39;00m\n\u001b[0;32m   1118\u001b[0m     taken \u001b[39m=\u001b[39m values\u001b[39m.\u001b[39mtake(\n\u001b[0;32m   1119\u001b[0m         indices, allow_fill\u001b[39m=\u001b[39mallow_fill, fill_value\u001b[39m=\u001b[39m\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_na_value\n\u001b[0;32m   1120\u001b[0m     )\n","File \u001b[1;32mc:\\ProgramData\\Miniconda3\\lib\\site-packages\\pandas\\core\\algorithms.py:1445\u001b[0m, in \u001b[0;36mtake\u001b[1;34m(arr, indices, axis, allow_fill, fill_value)\u001b[0m\n\u001b[0;32m   1440\u001b[0m     result \u001b[39m=\u001b[39m take_nd(\n\u001b[0;32m   1441\u001b[0m         arr, indices, axis\u001b[39m=\u001b[39maxis, allow_fill\u001b[39m=\u001b[39m\u001b[39mTrue\u001b[39;00m, fill_value\u001b[39m=\u001b[39mfill_value\n\u001b[0;32m   1442\u001b[0m     )\n\u001b[0;32m   1443\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[0;32m   1444\u001b[0m     \u001b[39m# NumPy style\u001b[39;00m\n\u001b[1;32m-> 1445\u001b[0m     result \u001b[39m=\u001b[39m arr\u001b[39m.\u001b[39;49mtake(indices, axis\u001b[39m=\u001b[39;49maxis)\n\u001b[0;32m   1446\u001b[0m \u001b[39mreturn\u001b[39;00m result\n","\u001b[1;31mKeyboardInterrupt\u001b[0m: "]}],"source":["forest = build_forest(training_data, n_trees, n_features, n_samples)"]},{"cell_type":"markdown","metadata":{"id":"dZb6EEYnnO05"},"source":["## Step4 : Make predictions with the random forest\n","> Note: Please print the f1-score of the predictions of each decision tree"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"UbHMZnMDnWpG"},"outputs":[],"source":["def make_prediction_forest(forest, data):\n","  \"\"\"\n","  This function will use the pre-trained random forest to make the predictions\n","  args:\n","  * forest: the random forest\n","  * data: the data used to predict\n","  return:\n","  * y_prediction: the predicted results\n","  \"\"\"\n","\n","\n","  return y_prediction"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Hcd70ubwgHq4"},"outputs":[{"ename":"NameError","evalue":"name 'y_prediction' is not defined","output_type":"error","traceback":["\u001b[1;31m---------------------------------------------------------------------------\u001b[0m","\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)","\u001b[1;32mc:\\Users\\KCChu\\Documents\\GitHub\\ML-Diabetes-Prediction\\hw2.ipynb Cell 50\u001b[0m in \u001b[0;36m<cell line: 1>\u001b[1;34m()\u001b[0m\n\u001b[1;32m----> <a href='vscode-notebook-cell:/c%3A/Users/KCChu/Documents/GitHub/ML-Diabetes-Prediction/hw2.ipynb#Y102sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m y_pred_test \u001b[39m=\u001b[39m make_prediction_forest(forest, x_test)\n","\u001b[1;32mc:\\Users\\KCChu\\Documents\\GitHub\\ML-Diabetes-Prediction\\hw2.ipynb Cell 50\u001b[0m in \u001b[0;36mmake_prediction_forest\u001b[1;34m(forest, data)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/KCChu/Documents/GitHub/ML-Diabetes-Prediction/hw2.ipynb#Y102sZmlsZQ%3D%3D?line=0'>1</a>\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mmake_prediction_forest\u001b[39m(forest, data):\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/KCChu/Documents/GitHub/ML-Diabetes-Prediction/hw2.ipynb#Y102sZmlsZQ%3D%3D?line=1'>2</a>\u001b[0m   \u001b[39m\"\"\"\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/KCChu/Documents/GitHub/ML-Diabetes-Prediction/hw2.ipynb#Y102sZmlsZQ%3D%3D?line=2'>3</a>\u001b[0m \u001b[39m  This function will use the pre-trained random forest to make the predictions\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/KCChu/Documents/GitHub/ML-Diabetes-Prediction/hw2.ipynb#Y102sZmlsZQ%3D%3D?line=3'>4</a>\u001b[0m \u001b[39m  args:\u001b[39;00m\n\u001b[1;32m   (...)\u001b[0m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/KCChu/Documents/GitHub/ML-Diabetes-Prediction/hw2.ipynb#Y102sZmlsZQ%3D%3D?line=7'>8</a>\u001b[0m \u001b[39m  * y_prediction: the predicted results\u001b[39;00m\n\u001b[0;32m      <a href='vscode-notebook-cell:/c%3A/Users/KCChu/Documents/GitHub/ML-Diabetes-Prediction/hw2.ipynb#Y102sZmlsZQ%3D%3D?line=8'>9</a>\u001b[0m \u001b[39m  \"\"\"\u001b[39;00m\n\u001b[1;32m---> <a href='vscode-notebook-cell:/c%3A/Users/KCChu/Documents/GitHub/ML-Diabetes-Prediction/hw2.ipynb#Y102sZmlsZQ%3D%3D?line=11'>12</a>\u001b[0m   \u001b[39mreturn\u001b[39;00m y_prediction\n","\u001b[1;31mNameError\u001b[0m: name 'y_prediction' is not defined"]}],"source":["y_pred_test = make_prediction_forest(forest, x_test)"]},{"cell_type":"markdown","metadata":{"id":"2ufa5bP9HveO"},"source":["## Step5 : Write the Output File\n","Save your predictions from the **random forest** in a csv file, named as **hw2_advanced.csv**"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"XdAQcE41JJYB"},"outputs":[],"source":["advanced = []\n","for i in range(len(y_pred_test)):\n","  advanced.append(y_pred_test[i])"]},{"cell_type":"code","execution_count":null,"metadata":{"id":"Pq121klSHwWO"},"outputs":[],"source":["advanced_path = 'hw2_advanced.csv'\n","pd.DataFrame(advanced).to_csv(advanced_path, header = None, index = None)"]}],"metadata":{"colab":{"collapsed_sections":[],"provenance":[]},"kernelspec":{"display_name":"Python 3.9.7 ('base')","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.9.7"},"vscode":{"interpreter":{"hash":"19d1d53a962d236aa061289c2ac16dc8e6d9648c89fe79f459ae9a3493bc67b4"}}},"nbformat":4,"nbformat_minor":0}
